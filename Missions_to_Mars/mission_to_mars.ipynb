{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setups up chromedriver and the browser control\n",
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "browser =  Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this can break from blackmagic, ask gretel\n",
    "# pulls the first index in list_text as variable recent\n",
    "recent = soup.find_all(\"div\", class_=\"list_text\")[0]\n",
    "# finds the title and paragraph text within recent\n",
    "news_title = recent.find(\"div\",class_=\"content_title\").text\n",
    "news_p = recent.find(\"div\",class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign url variable to next site\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "\n",
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locates .jpg link from feature image \n",
    "fancy_href = soup.find_all(\"a\", class_=\"button fancybox\")[0].get(\"data-fancybox-href\")\n",
    "# completes link url\n",
    "featured_image_url = 'https://www.jpl.nasa.gov' + fancy_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign url variable to next site\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "\n",
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "# this sleep step is longer to account for twitter restrictions\n",
    "browser.visit(url)\n",
    "time.sleep(30)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulls all possible tweets\n",
    "tweets = soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")\n",
    "# sets up empty weather update tweet list\n",
    "update_tweets = []\n",
    "# filters possible tweets to just those that include marker signifying an update\n",
    "for tweet in tweets:\n",
    "    if \"InSight sol\" in tweet.text:\n",
    "        update_tweets.append(tweet.text)\n",
    "# assigns latest update to new variable\n",
    "mars_weather = update_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign url variable to next site\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                              1\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.38 AU)\n",
       "5         Orbit Period:           687 days (1.9 years)\n",
       "6  Surface Temperature:                   -87 to -5 °C\n",
       "7         First Record:              2nd millennium BC\n",
       "8          Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.find_all(\"table\", class_=\"tablepress tablepress-id-p-mars\")\n",
    "mars_df = pd.read_html(str(table))[0]\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign url variable to next site\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "\n",
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulls urls for enhanced hemisphere images\n",
    "results = soup.find_all(\"a\", class_=\"itemLink product-item\")\n",
    "for result in results:\n",
    "    if result.text == 'Cerberus Hemisphere Enhanced':\n",
    "        cerb_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")\n",
    "    if result.text == 'Schiaparelli Hemisphere Enhanced':\n",
    "        schia_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")\n",
    "    if result.text == 'Syrtis Major Hemisphere Enhanced':\n",
    "        syrtm_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")\n",
    "    if result.text == 'Valles Marineris Hemisphere Enhanced':\n",
    "        vallm_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(cerb_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# collects url of full size image\n",
    "results = soup.find_all(\"a\")\n",
    "for result in results:\n",
    "    if result.text == 'Sample':\n",
    "        cerb_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(schia_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# collects url of full size image\n",
    "results = soup.find_all(\"a\")\n",
    "for result in results:\n",
    "    if result.text == 'Sample':\n",
    "        schia_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(syrtm_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# collects url of full size image\n",
    "results = soup.find_all(\"a\")\n",
    "for result in results:\n",
    "    if result.text == 'Sample':\n",
    "        syrtm_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets browser to visit the url and then wait to ensure all of the page loads\n",
    "browser.visit(vallm_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# builds soup object for data scraping\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# collects url of full size image\n",
    "results = soup.find_all(\"a\")\n",
    "for result in results:\n",
    "    if result.text == 'Sample':\n",
    "        vallm_url = 'https://astrogeology.usgs.gov' + result.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": vallm_url},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": cerb_url},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": schia_url},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": syrtm_url},\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
